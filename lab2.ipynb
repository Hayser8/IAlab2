{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Laboratorio 2** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Julio Garc√≠a Salas - 22076**\n",
    "#### **Sof√≠a Garc√≠a -22210**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ¬øPor qu√© el modelo de Naive Bayes se le considera ‚Äúnaive‚Äù?\n",
    "\n",
    "El modelo de Naive Bayes se considera \"naive\" (ingenuo) porque asume que todas las variables predictoras (features) son independientes entre s√≠, lo cual rara vez es cierto en la pr√°ctica. Esta suposici√≥n simplifica enormemente los c√°lculos, permitiendo una clasificaci√≥n r√°pida y eficiente, aunque en muchos casos la independencia condicional no se cumple completamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine (SVM)\n",
    "   - Explique la formulaci√≥n matem√°tica que se busca optimizar en Support Vector Machine.\n",
    "      El objetivo de **SVM** es encontrar un hiperplano que maximice la **margen** entre dos clases de datos.  \n",
    "      La formulaci√≥n matem√°tica de SVM se basa en minimizar la siguiente funci√≥n objetivo:\n",
    "\n",
    "      $$\n",
    "      \\min_{\\mathbf{w}, b} \\frac{1}{2} \\|\\mathbf{w}\\|^2\n",
    "      $$\n",
    "\n",
    "      ### Sujeto a las restricciones:\n",
    "\n",
    "      $$\n",
    "      y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1, \\quad \\forall i\n",
    "      $$\n",
    "\n",
    "      ### Donde:\n",
    "\n",
    "      **Vector de pesos:**  \n",
    "      $$\n",
    "      \\mathbf{w}\n",
    "      $$\n",
    "\n",
    "      **Sesgo (*bias*):**  \n",
    "      $$\n",
    "      b\n",
    "      $$\n",
    "\n",
    "      **Cada punto de datos de entrenamiento:**  \n",
    "      $$\n",
    "      \\mathbf{x}_i\n",
    "      $$\n",
    "\n",
    "      **Etiqueta de la clase:**  \n",
    "      $$\n",
    "      y_i \\in \\{+1, -1\\}\n",
    "      $$\n",
    "      \n",
    "\n",
    "      Si los datos no son perfectamente separables, se introduce un **t√©rmino de relajaci√≥n** con la funci√≥n de p√©rdida **hinge loss**, lo que lleva a la formulaci√≥n con variables de holgura $\\xi_i$:\n",
    "\n",
    "      $$\n",
    "      \\min_{\\mathbf{w}, b} \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^{n} \\xi_i\n",
    "      $$\n",
    "\n",
    "      ### Sujeto a:\n",
    "\n",
    "      $$\n",
    "      y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0\n",
    "      $$\n",
    "\n",
    "      Donde \\( C \\) es un hiperpar√°metro que controla la penalizaci√≥n por errores de clasificaci√≥n.\n",
    "   - Responda: ¬øc√≥mo funciona el truco del Kernel para este modelo?  \n",
    "     _(Lo que se espera de esta pregunta es que puedan explicar en sus propias palabras la f√≥rmula a la que llegamos que debemos optimizar de SVM en clase)._\n",
    "\n",
    "     El **truco del Kernel** permite transformar los datos a un espacio de mayor dimensi√≥n donde sean **linealmente separables**, sin necesidad de calcular expl√≠citamente la transformaci√≥n.  \n",
    "      En lugar de calcular la transformaci√≥n $ \\phi(x) $, se usa una funci√≥n **kernel** que eval√∫a el producto escalar en el espacio transformado:\n",
    "\n",
    "      $$\n",
    "      K(x_i, x_j) = \\phi(x_i) \\cdot \\phi(x_j)\n",
    "      $$\n",
    "\n",
    "      ### Ejemplos de funciones de kernel comunes:\n",
    "\n",
    "      - **Lineal**:\n",
    "        $$\n",
    "        K(x_i, x_j) = x_i \\cdot x_j\n",
    "        $$\n",
    "\n",
    "      - **Polin√≥mico**:\n",
    "        $$\n",
    "        K(x_i, x_j) = (x_i \\cdot x_j + c)^d\n",
    "        $$\n",
    "\n",
    "      - **RBF (Radial Basis Function)**:\n",
    "        $$\n",
    "        K(x_i, x_j) = \\exp(-\\gamma \\| x_i - x_j \\|^2)\n",
    "        $$\n",
    "\n",
    "      Esto permite que **SVM maneje datos no linealmente separables** de manera eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest\n",
    "   - **a.** ¬øQu√© tipo de ensemble learning es este modelo?\n",
    "   \n",
    "   **Random Forest** es un modelo de **Bagging (Bootstrap Aggregating)**, que es un tipo de **ensemble learning basado en agregaci√≥n**.  \n",
    "   - En **Bagging**, se generan m√∫ltiples modelos independientes (en este caso, √°rboles de decisi√≥n) entrenados en diferentes subconjuntos de los datos.  \n",
    "   - Luego, sus predicciones se combinan para mejorar la precisi√≥n y reducir la varianza del modelo.  \n",
    "   - En **clasificaci√≥n**, se usa **votaci√≥n mayoritaria**, y en **regresi√≥n**, se usa el **promedio de las predicciones**.\n",
    "\n",
    "   ---\n",
    "   - **b.** ¬øCu√°l es la idea general detr√°s de Random Forest?\n",
    "\n",
    "\n",
    "   La idea principal de **Random Forest** es entrenar **m√∫ltiples √°rboles de decisi√≥n** en subconjuntos aleatorios de los datos para reducir la varianza y mejorar la precisi√≥n.  \n",
    "El proceso general es el siguiente:\n",
    "\n",
    "1. **Bootstrap Sampling**: Se generan varios subconjuntos de los datos de entrenamiento mediante muestreo con reemplazo.\n",
    "2. **Entrenamiento de √Årboles de Decisi√≥n**: Cada √°rbol se entrena en un subconjunto diferente.\n",
    "3. **Selecci√≥n Aleatoria de Features**: En cada nodo del √°rbol, se selecciona aleatoriamente un subconjunto de variables para dividir los datos.\n",
    "4. **Combinaci√≥n de Predicciones**:\n",
    "   - En **clasificaci√≥n**, se usa **votaci√≥n mayoritaria** entre los √°rboles.\n",
    "   - En **regresi√≥n**, se promedian las predicciones de todos los √°rboles.\n",
    "   Esto hace que **Random Forest sea m√°s estable y generalice mejor** que un solo √°rbol de decisi√≥n, evitando el sobreajuste.\n",
    "\n",
    "---\n",
    "   - **c.** ¬øPor qu√© se busca baja correlaci√≥n entre los √°rboles de Random Forest?\n",
    "\n",
    "\n",
    "   Si los √°rboles dentro del bosque estuvieran altamente correlacionados, **cometer√≠an los mismos errores**, y el ensemble no mejorar√≠a la precisi√≥n.  \n",
    "Por eso, **se busca reducir la correlaci√≥n** entre los √°rboles mediante:\n",
    "- **Bootstrap Sampling**, para que cada √°rbol vea diferentes datos de entrenamiento.\n",
    "- **Selecci√≥n aleatoria de variables en cada nodo**, lo que obliga a los √°rboles a aprender caracter√≠sticas distintas.\n",
    "\n",
    "**Beneficios de una baja correlaci√≥n entre √°rboles:**\n",
    "\n",
    "\n",
    "‚úÖ **Mejora la generalizaci√≥n** ‚Üí Reduce el sobreajuste.  \n",
    "‚úÖ **Aumenta la estabilidad del modelo** ‚Üí Si un √°rbol falla, los otros pueden corregirlo.  \n",
    "‚úÖ **Reduce la varianza** ‚Üí Los errores individuales de los √°rboles se cancelan entre s√≠.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clasificaci√≥n de Mensajes como Spam o Ham usando Bayes/Laplace Smoothing**\n",
    "\n",
    "Este programa entrena un modelo basado en **Naive Bayes** con **Laplace Smoothing** para clasificar mensajes como **ham** (mensaje normal) o **spam** (correo no deseado).\n",
    "\n",
    "## **1. Requisitos del Programa**\n",
    "- Recibir como entrada un archivo llamado **\"entrenamiento.txt\"** (dataset de entrenamiento).\n",
    "- Usar **Naive Bayes** con **Laplace Smoothing** para clasificar mensajes.\n",
    "- Reportar m√©tricas de desempe√±o del modelo.\n",
    "- Clasificar nuevos mensajes como **spam** o **ham**.\n",
    "- **Restricciones:**\n",
    "  - Se permite entrenar **solo un modelo por dataset** (no se pueden cargar m√∫ltiples archivos).\n",
    "  - Se debe **limpiar el dataset** eliminando caracteres especiales y normalizando may√∫sculas/min√∫sculas.\n",
    "  - Cada l√≠nea del dataset representa **un mensaje** con su respectiva categor√≠a.\n",
    "  - Se debe dividir el dataset en **training y test**.\n",
    "  - Se permite usar **librer√≠as externas para la divisi√≥n de datos** (`sklearn`).\n",
    "  - ‚ùå **No se permite usar librer√≠as externas para la construcci√≥n del modelo**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Cargar el Dataset y Preprocesarlo**\n",
    "Primero, **cargamos el dataset** y aplicamos preprocesamiento eliminando caracteres especiales y convirtiendo el texto a min√∫sculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etiqueta</th>\n",
       "      <th>mensaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  etiqueta                                            mensaje\n",
       "0      ham  go until jurong point crazy available only in ...\n",
       "1      ham                            ok lar joking wif u oni\n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      ham        u dun say so early hor u c already then say\n",
       "4      ham  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def cargar_dataset(nombre_archivo):\n",
    "    datos = []\n",
    "    with open(nombre_archivo, \"r\", encoding=\"utf-8\") as file:\n",
    "        for linea in file:\n",
    "            etiqueta, mensaje = linea.strip().split(\"\\t\")  \n",
    "            mensaje = limpiar_texto(mensaje)  \n",
    "            datos.append((etiqueta, mensaje))\n",
    "    return pd.DataFrame(datos, columns=[\"etiqueta\", \"mensaje\"])\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)  \n",
    "    texto = texto.lower().strip()  \n",
    "    return texto\n",
    "\n",
    "df = cargar_dataset(\"entrenamiento.txt\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Dividir en Training y Test**\n",
    "\n",
    "Se divide el dataset en 80% training y 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del dataset de entrenamiento: 4452\n",
      "Tama√±o del dataset de prueba: 1113\n",
      "Distribuci√≥n en el dataset de entrenamiento:\n",
      "etiqueta\n",
      "ham     3862\n",
      "spam     590\n",
      "Name: count, dtype: int64\n",
      "Distribuci√≥n en el dataset de prueba:\n",
      "etiqueta\n",
      "ham     956\n",
      "spam    157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"mensaje\"], df[\"etiqueta\"], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"Tama√±o del dataset de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Tama√±o del dataset de prueba: {len(X_test)}\")\n",
    "\n",
    "print(\"Distribuci√≥n en el dataset de entrenamiento:\")\n",
    "print(y_train.value_counts()) \n",
    "print(\"Distribuci√≥n en el dataset de prueba:\")\n",
    "print(y_test.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Implementar el modelo de Bayes con Laplace Smoothing sin uso de librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayesSpamClassifier:\n",
    "    def __init__(self, laplace=0.1):\n",
    "        # Factor de laplace smoothing\n",
    "        self.laplace = laplace  \n",
    "        self.vocabulario = set()\n",
    "        self.palabras_spam = defaultdict(int)\n",
    "        self.palabras_ham = defaultdict(int)\n",
    "        self.total_spam = 0\n",
    "        self.total_ham = 0\n",
    "        self.num_spam = 0\n",
    "        self.num_ham = 0\n",
    "\n",
    "    def entrenar(self, X, y):\n",
    "        for mensaje, etiqueta in zip(X, y):\n",
    "            palabras = mensaje.split()\n",
    "            self.vocabulario.update(palabras)\n",
    "            if etiqueta == \"spam\":\n",
    "                self.num_spam += 1\n",
    "                for palabra in palabras:\n",
    "                    self.palabras_spam[palabra] += 1\n",
    "                    self.total_spam += 1\n",
    "            else:\n",
    "                self.num_ham += 1\n",
    "                for palabra in palabras:\n",
    "                    self.palabras_ham[palabra] += 1\n",
    "                    self.total_ham += 1\n",
    "\n",
    "    def predecir(self, mensaje):\n",
    "        palabras = mensaje.split()\n",
    "        vocab_size = len(self.vocabulario)\n",
    "\n",
    "        # Probabilidades iniciales\n",
    "        p_spam = np.log(self.num_spam / (self.num_spam + self.num_ham))\n",
    "        p_ham = np.log(self.num_ham / (self.num_spam + self.num_ham))\n",
    "\n",
    "        # Calcular probabilidades con Laplace Smoothing\n",
    "        for palabra in palabras:\n",
    "            p_spam += np.log((self.palabras_spam[palabra] + self.laplace) / (self.total_spam + vocab_size * self.laplace))\n",
    "            p_ham += np.log((self.palabras_ham[palabra] + self.laplace) / (self.total_ham + vocab_size * self.laplace))\n",
    "\n",
    "        return \"spam\" if p_spam > p_ham else \"ham\"\n",
    "\n",
    "\n",
    "modelo = NaiveBayesSpamClassifier()\n",
    "modelo.entrenar(X_train, y_train)\n",
    "print(\"Modelo entrenado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Evaluar Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el modelo usamos:\n",
    "- **Precisi√≥n (Precision)**: Mide cu√°ntos de los mensajes clasificados como spam realmente lo son.\n",
    "- **Recall (Sensibilidad)**: Mide cu√°ntos de los mensajes spam fueron detectados correctamente.\n",
    "- **F1-score**: Es el balance entre precisi√≥n y recall.\n",
    "\n",
    "Estas m√©tricas son importantes en clasificaci√≥n de spam, ya que un **bajo recall** significa que el modelo no detecta suficiente spam, y un **bajo precision** significa que clasifica err√≥neamente mensajes ham como spam.ara evaluar el rendimiento del modelo, calculamos precisi√≥n, recall y f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.99       963\n",
      "        spam       0.89      0.96      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1113\n",
      "   macro avg       0.94      0.97      0.96      1113\n",
      "weighted avg       0.98      0.98      0.98      1113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_pred = [modelo.predecir(mensaje) for mensaje in X_test]\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"ham\", \"spam\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Predicci√≥n Mensajes Futuros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì© Ingrese mensajes para clasificar. Escriba 'salir' para terminar.\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: amo k\n",
      "üìå Probabilidad de Spam: 0.0033\n",
      "üìå Probabilidad de Ham: 0.9967\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "‚ö†Ô∏è Palabras no vistas en el entrenamiento: amo\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç **Resultados de clasificaci√≥n:**\n",
      "üì© Mensaje ingresado: \n",
      "üìå Probabilidad de Spam: 0.1312\n",
      "üìå Probabilidad de Ham: 0.8688\n",
      "‚úÖ **El mensaje ha sido clasificado como: HAM**\n",
      "\n",
      "==================================================\n",
      "\n",
      "üö™ Saliendo del programa...\n"
     ]
    }
   ],
   "source": [
    "def predecir_probabilidades(modelo, mensaje):\n",
    "    mensaje = limpiar_texto(mensaje)  \n",
    "    palabras = mensaje.split()\n",
    "    vocab_size = len(modelo.vocabulario)\n",
    "\n",
    "    p_spam_log = np.log(modelo.num_spam / (modelo.num_spam + modelo.num_ham))\n",
    "    p_ham_log = np.log(modelo.num_ham / (modelo.num_spam + modelo.num_ham))\n",
    "\n",
    "    palabras_no_vistas = [palabra for palabra in palabras if palabra not in modelo.vocabulario]\n",
    "\n",
    "    for palabra in palabras:\n",
    "        p_spam_log += np.log((modelo.palabras_spam[palabra] + modelo.laplace) / (modelo.total_spam + vocab_size * modelo.laplace))\n",
    "        p_ham_log += np.log((modelo.palabras_ham[palabra] + modelo.laplace) / (modelo.total_ham + vocab_size * modelo.laplace))\n",
    "\n",
    "    p_spam = np.exp(p_spam_log)\n",
    "    p_ham = np.exp(p_ham_log)\n",
    "\n",
    "    total = p_spam + p_ham\n",
    "    p_spam /= total\n",
    "    p_ham /= total\n",
    "\n",
    "    clasificacion = \"spam\" if p_spam > p_ham else \"ham\"\n",
    "\n",
    "    return p_spam, p_ham, clasificacion, palabras_no_vistas\n",
    "\n",
    "modelo = NaiveBayesSpamClassifier(laplace=0.1)\n",
    "modelo.entrenar(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"üì© Ingrese mensajes para clasificar. Escriba 'salir' para terminar.\")\n",
    "\n",
    "while True:\n",
    "    mensaje = input(\"‚úèÔ∏è  Escriba un mensaje: \").strip()\n",
    "    if mensaje.lower() == \"salir\":\n",
    "        print(\"üö™ Saliendo del programa...\")\n",
    "        break\n",
    "\n",
    "    p_spam, p_ham, clasificacion, palabras_no_vistas = predecir_probabilidades(modelo, mensaje)\n",
    "\n",
    "    print(f\"\\nüîç **Resultados de clasificaci√≥n:**\")\n",
    "    print(f\"üì© Mensaje ingresado: {mensaje}\")\n",
    "    print(f\"üìå Probabilidad de Spam: {p_spam:.4f}\")\n",
    "    print(f\"üìå Probabilidad de Ham: {p_ham:.4f}\")\n",
    "    print(f\"‚úÖ **El mensaje ha sido clasificado como: {clasificacion.upper()}**\")\n",
    "    \n",
    "    if palabras_no_vistas:\n",
    "        print(f\"‚ö†Ô∏è Palabras no vistas en el entrenamiento: {', '.join(palabras_no_vistas)}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Evaluaci√≥n Modelo con librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del dataset de entrenamiento: 4452\n",
      "Tama√±o del dataset de prueba: 1113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower().strip()\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)  \n",
    "    return texto\n",
    "\n",
    "def cargar_dataset(nombre_archivo):\n",
    "    datos = []\n",
    "    with open(nombre_archivo, \"r\", encoding=\"utf-8\") as file:\n",
    "        for linea in file:\n",
    "            etiqueta, mensaje = linea.strip().split(\"\\t\")  \n",
    "            mensaje = limpiar_texto(mensaje)  \n",
    "            datos.append((etiqueta, mensaje))\n",
    "    return pd.DataFrame(datos, columns=[\"etiqueta\", \"mensaje\"])\n",
    "\n",
    "df = cargar_dataset(\"entrenamiento.txt\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"mensaje\"], df[\"etiqueta\"], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tama√±o del dataset de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Tama√±o del dataset de prueba: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justificaci√≥n de las m√©tricas utilizadas**\n",
    "- **Precisi√≥n (Precision)**: Mide cu√°ntos de los mensajes clasificados como spam realmente lo son.\n",
    "  ‚Üí Es importante en este problema porque un **falso positivo** (clasificar un mensaje ham como spam) es cr√≠tico.\n",
    "  \n",
    "- **Recall (Sensibilidad)**: Mide cu√°ntos de los mensajes spam fueron detectados correctamente.\n",
    "  ‚Üí Un **bajo recall** significa que el modelo no detecta suficiente spam.\n",
    "\n",
    "- **F1-score**: Es el balance entre precisi√≥n y recall.\n",
    "  ‚Üí Se usa en problemas desbalanceados como clasificaci√≥n de spam, donde queremos reducir **falsos positivos y falsos negativos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä **Evaluaci√≥n del modelo con `MultinomialNB` de sklearn:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.97       950\n",
      "        spam       1.00      0.67      0.80       163\n",
      "\n",
      "    accuracy                           0.95      1113\n",
      "   macro avg       0.97      0.83      0.89      1113\n",
      "weighted avg       0.95      0.95      0.95      1113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "modelo_sklearn = make_pipeline(vectorizer, MultinomialNB())\n",
    "modelo_sklearn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sklearn = modelo_sklearn.predict(X_test)\n",
    "\n",
    "print(\"üìä **Evaluaci√≥n del modelo con `MultinomialNB` de sklearn:**\")\n",
    "print(classification_report(y_test, y_pred_sklearn, target_names=[\"ham\", \"spam\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comparaci√≥n de Modelos de Naive Bayes**\n",
    "\n",
    "## **1. Introducci√≥n**\n",
    "Se entrenaron dos modelos de Naive Bayes para clasificar mensajes como spam o ham:\n",
    "- **Modelo sin librer√≠as**: Implementado manualmente con Laplace Smoothing.\n",
    "- **Modelo con `MultinomialNB` de sklearn** utilizando `TfidfVectorizer`.\n",
    "\n",
    "El dataset est√° desbalanceado:\n",
    "- **Entrenamiento:** 3862 ham, 590 spam.\n",
    "- **Prueba:** 956 ham, 157 spam.\n",
    "\n",
    "## **2. Resultados**\n",
    "### **Modelo sin librer√≠as**\n",
    "```\n",
    "Precisi√≥n: Ham 0.99 | Spam 0.89\n",
    "Recall: Ham 0.98 | Spam 0.96\n",
    "F1-score: Ham 0.99 | Spam 0.92\n",
    "Accuracy: 0.98\n",
    "```\n",
    "\n",
    "### **Modelo con `MultinomialNB` y `TfidfVectorizer`**\n",
    "```\n",
    "Precisi√≥n: Ham 0.95 | Spam 1.00\n",
    "Recall: Ham 1.00 | Spam 0.67\n",
    "F1-score: Ham 0.97 | Spam 0.80\n",
    "Accuracy: 0.95\n",
    "```\n",
    "\n",
    "## **3. ¬øCu√°l implementaci√≥n fue mejor?**\n",
    "- **Si el objetivo es detectar spam, el modelo sin librer√≠as es mejor** (96% recall en spam vs. 67% en `MultinomialNB`).\n",
    "- **Si el objetivo es generalizar mejor y evitar sobreajuste, `MultinomialNB` con `TfidfVectorizer` es mejor** (mejor equilibrio entre clases y menos sesgo).\n",
    "\n",
    "## **4. ¬øPor qu√© existe esta diferencia?**\n",
    "1. **Dataset desbalanceado**: `MultinomialNB` tiende a favorecer ham, lo que reduce su recall en spam.\n",
    "2. **C√°lculo de probabilidades**: `MultinomialNB` usa `TfidfVectorizer`, que normaliza la frecuencia de las palabras, mientras que el modelo manual usa conteo directo.\n",
    "3. **Sobreajuste del modelo sin librer√≠as**: Su alto recall en spam puede deberse a que ha memorizado palabras clave espec√≠ficas en lugar de generalizar.\n",
    "4. **Diferencia en representaci√≥n de texto**: `TfidfVectorizer` reduce el peso de palabras muy frecuentes y resalta t√©rminos distintivos, lo que afecta la clasificaci√≥n de spam.\n",
    "\n",
    "## **5. Conclusi√≥n**\n",
    "- **El modelo sin librer√≠as es mejor para detectar spam, pero puede estar sobreajustado.**\n",
    "- **`MultinomialNB` con `TfidfVectorizer` generaliza mejor, pero pierde spam.**\n",
    "- **Se recomienda ajustar `MultinomialNB` con oversampling de spam y mejor preprocesamiento para mejorar su recall.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Clasificaci√≥n de Partidas de League of Legends**\n",
    "\n",
    "## **Introducci√≥n**\n",
    "League of Legends es un juego online multijugador categorizado como MOBA (Multiplayer Online Battle Arena). En este juego, dos equipos (azul y rojo) de cinco jugadores compiten con el objetivo de derribar el Nexus enemigo.\n",
    "\n",
    "El prop√≥sito de este proyecto es construir un modelo de clasificaci√≥n que prediga si el equipo azul gana una partida, utilizando un conjunto de datos de League of Legends. \n",
    "\n",
    "## **Exploraci√≥n de Datos**\n",
    "En esta secci√≥n realizaremos una exploraci√≥n inicial del dataset para comprender su estructura y prepararlo para el modelo de clasificaci√≥n.\n",
    "\n",
    "### **1. Carga de Datos**\n",
    "- Cargar el dataset en un DataFrame de Pandas.\n",
    "- Inspeccionar las primeras filas y verificar informaci√≥n general de las variables.\n",
    "\n",
    "### **2. Preprocesamiento de Datos**\n",
    "- **Codificaci√≥n de variables**: Transformar variables categ√≥ricas en num√©ricas si es necesario.\n",
    "- **Balanceo del dataset**: Verificar si la variable objetivo est√° balanceada y, si no lo est√°, aplicar t√©cnicas de balanceo.\n",
    "- **Escalado de variables**: Normalizar o estandarizar las caracter√≠sticas si es necesario.\n",
    "- **Selecci√≥n de caracter√≠sticas**: Determinar qu√© variables son m√°s relevantes para el modelo.\n",
    "\n",
    "## **Divisi√≥n del Dataset**\n",
    "El dataset se dividir√° en:\n",
    "- **80%** para entrenamiento.\n",
    "- **20%** para prueba.\n",
    "- **Opcionalmente**, si se requiere, el conjunto de prueba se subdividir√° en **10%** para validaci√≥n y **90%** para evaluaci√≥n.\n",
    "\n",
    "## **Construcci√≥n del Modelo**\n",
    "- Selecci√≥n del modelo de clasificaci√≥n adecuado.\n",
    "- Entrenamiento del modelo con los datos preparados.\n",
    "- Evaluaci√≥n del desempe√±o del modelo con m√©tricas adecuadas.\n",
    "\n",
    "## **M√©trica de Desempe√±o**\n",
    "Para evaluar el modelo, se seleccionar√° una m√©trica de desempe√±o basada en la naturaleza del problema:\n",
    "- **Exactitud (Accuracy)**: √ötil si el dataset est√° balanceado.\n",
    "- **F1-Score**: Adecuado en caso de un dataset desbalanceado.\n",
    "- **ROC-AUC**: Para evaluar la capacidad del modelo de distinguir entre clases positivas y negativas.\n",
    "\n",
    "Se justificar√° la elecci√≥n de la m√©trica en funci√≥n del an√°lisis del dataset.\n",
    "\n",
    "## **Conclusi√≥n**\n",
    "Se analizar√°n los resultados obtenidos y se discutir√°n mejoras posibles en la clasificaci√≥n de partidas de League of Legends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Paso 1: Carga y Exploraci√≥n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>blueWins</th>\n",
       "      <th>blueWardsPlaced</th>\n",
       "      <th>blueWardsDestroyed</th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>...</th>\n",
       "      <th>redTowersDestroyed</th>\n",
       "      <th>redTotalGold</th>\n",
       "      <th>redAvgLevel</th>\n",
       "      <th>redTotalExperience</th>\n",
       "      <th>redTotalMinionsKilled</th>\n",
       "      <th>redTotalJungleMinionsKilled</th>\n",
       "      <th>redGoldDiff</th>\n",
       "      <th>redExperienceDiff</th>\n",
       "      <th>redCSPerMin</th>\n",
       "      <th>redGoldPerMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4519157822</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16567</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17047</td>\n",
       "      <td>197</td>\n",
       "      <td>55</td>\n",
       "      <td>-643</td>\n",
       "      <td>8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1656.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4523371949</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17620</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17438</td>\n",
       "      <td>240</td>\n",
       "      <td>52</td>\n",
       "      <td>2908</td>\n",
       "      <td>1173</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4521474530</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17285</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17254</td>\n",
       "      <td>203</td>\n",
       "      <td>28</td>\n",
       "      <td>1172</td>\n",
       "      <td>1033</td>\n",
       "      <td>20.3</td>\n",
       "      <td>1728.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4524384067</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17961</td>\n",
       "      <td>235</td>\n",
       "      <td>47</td>\n",
       "      <td>1321</td>\n",
       "      <td>7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1647.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4436033771</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18313</td>\n",
       "      <td>225</td>\n",
       "      <td>67</td>\n",
       "      <td>1004</td>\n",
       "      <td>-230</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1740.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gameId  blueWins  blueWardsPlaced  blueWardsDestroyed  blueFirstBlood  \\\n",
       "0  4519157822         0               28                   2               1   \n",
       "1  4523371949         0               12                   1               0   \n",
       "2  4521474530         0               15                   0               0   \n",
       "3  4524384067         0               43                   1               0   \n",
       "4  4436033771         0               75                   4               0   \n",
       "\n",
       "   blueKills  blueDeaths  blueAssists  blueEliteMonsters  blueDragons  ...  \\\n",
       "0          9           6           11                  0            0  ...   \n",
       "1          5           5            5                  0            0  ...   \n",
       "2          7          11            4                  1            1  ...   \n",
       "3          4           5            5                  1            0  ...   \n",
       "4          6           6            6                  0            0  ...   \n",
       "\n",
       "   redTowersDestroyed  redTotalGold  redAvgLevel  redTotalExperience  \\\n",
       "0                   0         16567          6.8               17047   \n",
       "1                   1         17620          6.8               17438   \n",
       "2                   0         17285          6.8               17254   \n",
       "3                   0         16478          7.0               17961   \n",
       "4                   0         17404          7.0               18313   \n",
       "\n",
       "   redTotalMinionsKilled  redTotalJungleMinionsKilled  redGoldDiff  \\\n",
       "0                    197                           55         -643   \n",
       "1                    240                           52         2908   \n",
       "2                    203                           28         1172   \n",
       "3                    235                           47         1321   \n",
       "4                    225                           67         1004   \n",
       "\n",
       "   redExperienceDiff  redCSPerMin  redGoldPerMin  \n",
       "0                  8         19.7         1656.7  \n",
       "1               1173         24.0         1762.0  \n",
       "2               1033         20.3         1728.5  \n",
       "3                  7         23.5         1647.8  \n",
       "4               -230         22.5         1740.4  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "file_path = \"high_diamond_ranked_10min.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueGoldDiff</th>\n",
       "      <th>blueExperienceDiff</th>\n",
       "      <th>blueWins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256215</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.191194</td>\n",
       "      <td>-0.593312</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.483590</td>\n",
       "      <td>-0.520410</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.544323</td>\n",
       "      <td>0.013862</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.415112</td>\n",
       "      <td>0.137276</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blueGoldDiff  blueExperienceDiff  blueWins\n",
       "0      0.256215            0.013341        -1\n",
       "1     -1.191194           -0.593312        -1\n",
       "2     -0.483590           -0.520410        -1\n",
       "3     -0.544323            0.013862        -1\n",
       "4     -0.415112            0.137276        -1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"blueWins\"\n",
    "features = [\"blueGoldDiff\", \"blueExperienceDiff\"]\n",
    "data = data[features + [target]]\n",
    "\n",
    "\n",
    "data[features] = (data[features] - data[features].mean()) / data[features].std()\n",
    "data[target] = data[target].apply(lambda x: 1 if x == 1 else -1)\n",
    "\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3: Divisi√≥n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7903, 2), (988, 2), (988, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
